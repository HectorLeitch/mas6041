{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letters\n",
    "\n",
    "Run the source code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"code\\letters.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', 'chi', 'chic', 'chichi', 'chili', 'chill', 'chilli', 'chilly', 'chit', 'chou', 'ci', 'city', 'cl', 'clio', 'clot', 'cloth', 'clotho', 'clout', 'cloy', 'clutch', 'co', 'cocci', 'coccyx', 'coil', 'col', 'colic', 'colo', 'colt', 'coo', 'cool', 'coolly', 'coot', 'cot', 'couch', 'cox', 'coy', 'coyly', 'cthulhu', 'cu', 'cull', 'cult', 'cut', 'cyclic', 'h', 'hi', 'hill', 'hilly', 'hilt', 'hit', 'hitch', 'ho', 'hohhot', 'holly', 'holt', 'holy', 'hooch', 'hoot', 'hootch', 'hot', 'hotly', 'huh', 'hui', 'hull', 'hut', 'hutch', 'hutu', 'i', 'icily', 'icy', 'ill', 'illicit', 'illicitly', 'io', 'it', 'itch', 'itchy', 'ito', 'j', 'jill', 'jilt', 'jo', 'jollity', 'jolly', 'jolt', 'jot', 'joy', 'juicy', 'jul', 'julio', 'july', 'jut', 'l', 'li', 'licit', 'lilith', 'lilly', 'lilt', 'lily', 'lit', 'litchi', 'lo', 'loci', 'loco', 'loll', 'loot', 'lot', 'loth', 'lott', 'lotto', 'lou', 'lout', 'lox', 'lt', 'lu', 'lucio', 'lucy', 'lull', 'lully', 'lulu', 'lyly', 'lyx', 'o', 'occult', 'oct', 'oh', 'ohio', 'oho', 'oil', 'oilcloth', 'oily', 'otto', 'ouch', 'out', 'ox', 't', 'tc', 'th', 'tho', 'thoth', 'thou', 'thy', 'ti', 'tic', 'till', 'tillich', 'tilt', 'tit', 'tito', 'tl', 'to', 'toil', 'tojo', 'toll', 'too', 'tool', 'toot', 'tooth', 'toothy', 'tot', 'toto', 'touch', 'touchy', 'tout', 'toxic', 'toxicity', 'toy', 'tull', 'tut', 'tutu', 'tux', 'ty', 'tycho', 'u', 'uh', 'utility', 'x', 'y', 'yo', 'you', 'youth'] [4, 202, 5526, 269064, 22829, 96034, 257085, 418136, 10850, 12665, 15, 3645, 70, 6846, 11323, 113810, 919065, 129782, 3337, 1197728, 59, 20508, 1645659, 8166, 785, 60680, 7440, 11433, 664, 8650, 418598, 11312, 1027, 108959, 1269, 301, 37569, 17172170, 103, 8815, 11477, 1071, 667341, 7, 18, 8730, 38012, 11392, 986, 108797, 62, 1371839, 38056, 11436, 3450, 108478, 11315, 1197236, 1030, 38298, 953, 227, 8818, 1074, 108885, 13053, 1, 37434, 287, 793, 14394227, 560035015, 56, 89, 9890, 39172, 694, 3, 8726, 11388, 58, 4854941, 38052, 11432, 1026, 300, 34829, 828, 75364, 3490, 1070, 6, 17, 118960, 1246559, 38011, 11391, 3405, 985, 269847, 61, 1876, 7200, 8773, 11314, 1029, 10346, 11677, 84882, 1150, 11798, 1271, 94, 105, 75125, 3251, 8817, 38099, 12810, 3416, 1238, 5, 1388766, 1017, 82, 6858, 687, 742, 151481852, 3404, 7716, 9905, 1072, 115, 8, 52, 85, 690, 113825, 12669, 327, 19, 503, 8731, 13068503, 11393, 987, 7642, 74, 63, 8170, 7081, 8775, 668, 8654, 11316, 113803, 435905, 1031, 7686, 108963, 431065, 11800, 61168, 53369049, 305, 8819, 1075, 13054, 1317, 30, 83036, 9, 86, 4854375, 10, 2, 57, 1146, 114281]\n"
     ]
    }
   ],
   "source": [
    "words_3x3, numbers_3x3 = make_2vocab(file='words_3x3.txt')\n",
    "print(words_3x3, numbers_3x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.1\n",
    "\n",
    "Here we demonstrate the kernels to detect a letter from its representation in a 3x3 grid. Modify `letter` to any of the given letters and check the output is the one-hot encoding of the letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G = \n",
      "[[1 1 1]\n",
      " [1 0 0]\n",
      " [1 1 1]]\n",
      "output = [[[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "# The letters in order are i,y,j,c,o,l,h,t,u,x\n",
    "letter = 'c'\n",
    "\n",
    "G = letter_pixels[letter]\n",
    "print(f\"G = \\n{G}\")\n",
    "G = tf.convert_to_tensor(G.reshape(1,3,3))\n",
    "M = make_explicit_model()\n",
    "print(f\"output = {M.predict(G, verbose=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check that it rejects non-letters by setting the output to all zeros. A random choice of `G` will give us a non-letter 502 times out of 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G = \n",
      "[[1 1 0]\n",
      " [1 1 0]\n",
      " [0 1 1]]\n",
      "output = [[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "G = np.random.choice(a=[0, 1], size=(3, 3), p=[0.5, 0.5])\n",
    "print(f\"G = \\n{G}\")\n",
    "G = tf.convert_to_tensor(G.reshape(1,3,3))\n",
    "M = make_explicit_model()\n",
    "print(f\"output = {M.predict(G, verbose=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the function below tests whether the model output classifies all possible 512 3x3 images correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_explicit_model(M=M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.2\n",
    "\n",
    "We now demonstrate the convolutional model using the kernels from the model above to search for letters in a grid of height $h$ and width $w$. The variable `word` can be set to any word containing our specified letters, and the function `make_ragged_grid()` will choose appropriate values for $h$ and $w$ and create a grid containing the word.\n",
    "\n",
    "The output of the model contains a series of one-hot vectors showing the detected letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADRUlEQVR4nO3cwW6DMBQAwbri/3/59ZpLJdIKHLEzZyQesUlWPmTNzHwBAFnfuwcAAPYSAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxB1nL1xrXTnHY/gPp89y9b613sATOBkAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABA3LF7gFczs3sEgMdba11+jzu+z69+jtJvkpMBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxB27B3i11to9wr/NzO4R4G1PePfu8JT3+47nuGNPPWU9PoGTAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4o6zF87MlXPAJezbc+74nNZal9/DesPfOBkAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABA3LF7AACeZ2Z2j8AbnAwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAg7tg9ANAwM7tHAH7hZAAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMT9AKYgMkN+3WNaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "GM = make_conv_model(G.shape[1], G.shape[2])\n",
    "print(GM.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.3\n",
    "\n",
    "This example demonstrates the model above with the additional of a layer to count up the occurences of each letter. The output is a single vector containing the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADO0lEQVR4nO3cQXKDQBAEQY+D/395fPXdgrVUmR+gERJRsQfN7u4XAJD1fXoAAHCWGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIO46PQA4b2ZOT3gL/qONT+VkAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHHX6QF0zczt19jd26/xCZ74nDxv+L+cDABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACDuOj3gt5k5PeEt7O7pCcAbe+Jd+8R76u77KL1rnQwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABB3nR7wtN09PQGS/Pb+jyeexczcfg3fqddxMgAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIC46/SAp83M6Ql/trunJ7zEp9wHwLtzMgAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIC42d09PQIAOMfJAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiPsBzJwwQiaMZPsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]]]]\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "SM = make_sum_model(G.shape[1], G.shape[2])\n",
    "print(SM.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.4\n",
    "\n",
    "The following code demonstrates the model that recognises words. The output will be a series of integers from 1 to 10 representing each letter. The sequence is sorted so that the detected letters are moved to the front of the sequence, and the zeros are moved to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADOklEQVR4nO3YQWrDQBQFQU3Q/a/8szVeGYI0sbrqAOZJY0Eza2bmAACyfnYPAAD2EgMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIO3cPeLXW2j3hK8zM7gk8jG/vM0/59u447zve1dXP8ZTz/oSbAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSduwfcbWZ2T+BGa61Lf/8p/6c7nuPqsziO55zH1Zw379wMAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQd+4ecLe11u4JfzYzuycA8CBuBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABB37h7wamZ2TwAu4vtucd7fxc0AAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4s7dA+BKM7N7AsC/52YAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADE/QLViTJBgN9FIgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 1. 8. 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "GRUM = make_gru_model(G.shape[1], G.shape[2])\n",
    "print(GRUM.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the output at various stages to verify the model is working as described. The code below shows the output of layer $\\mathcal{L}^{\\left[3\\right]}$, which is the sequence $\\left\\{x_t\\right\\}_{t=1}^{w_g}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002198BA2AEF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[[4.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [8.]\n",
      "  [0.]\n",
      "  [2.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_integers = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[5].output)\n",
    "print(GRUM_integers.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to produce the sequence of indicators in layer $\\mathcal{L}^{\\left[5\\right]}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 21 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002198BA2BBE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[[1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_indicator = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[7].output)\n",
    "print(GRUM_indicator.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to produce the series of positional indicators $\\left\\{\\pmb{p}_t\\right\\}_{t=1}^{w_g}$ in layer $\\mathcal{L}^{\\left[8\\right]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_position = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[10].output)\n",
    "print(GRUM_position.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full combination passed to the final GRU layer is then as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 1. 0. 0. 0. 0.]\n",
      "  [8. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [2. 0. 0. 0. 1. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_final_input = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[13].output)\n",
    "print(GRUM_final_input.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.5\n",
    "\n",
    "The alternative model below shows how the sequence $\\left\\{\\pmb{p}_t\\right\\}_{t=1}^{w_g}$ could also be created in a more intuitive way using a GRU layer with an initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADL0lEQVR4nO3YQW7CQBBFwUzE/a/c2bILUYRb5lWd4MPY1tOcmZkvACDre3sAALBLDABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACDusT3g2Tlne8ItzMz2hNt49zPlLIBP4GYAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcY/tAVebme0JkHTO2Z5wC5/yjbrivN/9X33Cb3iVmwEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOIe2wOuds7ZnvBvM7M9Af7siuf23e+3d+91zvte3AwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAg7rE94NnMbE/gw3imAH7nZgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxZ2ZmewQAsMfNAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiPsBEoswQBvcq70AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to GRU layer:\n",
      " [[[1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]]]\n",
      "Output of GRU layer:\n",
      " [[[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0.]]]\n",
      "Final output:\n",
      " [[4. 1. 8. 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "GRUaM = make_alt_gru_model(G.shape[1], G.shape[2])\n",
    "\n",
    "GRUaM_indicator = tf.keras.Model(inputs=GRUaM.input, outputs=GRUaM.layers[7].output)\n",
    "print(f\"Input to GRU layer:\\n {GRUaM_indicator.predict(G, verbose=0)}\")\n",
    "\n",
    "GRUaM_position = tf.keras.Model(inputs=GRUaM.input, outputs=GRUaM.layers[8].output)\n",
    "print(f\"Output of GRU layer:\\n {GRUaM_position.predict(G, verbose=0)}\")\n",
    "\n",
    "print(f\"Final output:\\n {GRUaM.predict(G, verbose=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.6\n",
    "\n",
    "A full model with lookup layers added can be tested below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADJ0lEQVR4nO3cQWqEQBBA0XTw/leubIesHCbaxP/eWqRQGz61cM3MfAEAWd+7BwAA9hIDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEHWcvXGtdOcdj+IcTAP+NzQAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADijt0DvJqZ3SPwMGutS+//lG/26uf0FN73eXc8K+f779gMAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIO7YPcCrtdbuET42M7tHgLfd8d3ecb6dv3O8b36zGQCAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIO44e+HMXDkHALCJzQAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADi1szM7iEAgH1sBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIC4H5jCLUMqxw2dAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "FM = make_full_model(G.shape[1], G.shape[2])\n",
    "# decode() just takes the raw string from the tensor object\n",
    "[print(z.decode()) for z in FM.predict(G, verbose=0).reshape(1,)]\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure code\n",
    "\n",
    "The following code produce the figures contained in this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.random.set_seed(210138711)\n",
    "\n",
    "word = 'city'\n",
    "G = G_orig = make_ragged_grid(word)\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "FM = make_full_model(G.shape[1], G.shape[2])\n",
    "word_out = [z.decode() for z in FM.predict(G, verbose=0).reshape(1,)]\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G_orig, cmap='gray')\n",
    "plt.title(f'word in = {word}, word out = {word_out}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
