{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letters\n",
    "\n",
    "Run the source code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"code\\letters.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.1\n",
    "\n",
    "Here we demonstrate the kernels to detect a letter from its representation in a 3x3 grid. Modify `letter` to any of the given letters and check the output is the one-hot encoding of the letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G = \n",
      "[[1 1 1]\n",
      " [1 0 0]\n",
      " [1 1 1]]\n",
      "output = [[[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "# The letters in order are i,y,j,c,o,l,h,t,u,x\n",
    "letter = 'c'\n",
    "\n",
    "G = letter_pixels[letter]\n",
    "print(f\"G = \\n{G}\")\n",
    "G = tf.convert_to_tensor(G.reshape(1,3,3))\n",
    "M = make_explicit_model()\n",
    "print(f\"output = {M.predict(G, verbose=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check that it rejects non-letters by setting the output to all zeros. A random choice of `G` will give us a non-letter 502 times out of 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G = \n",
      "[[1 0 0]\n",
      " [1 1 1]\n",
      " [1 0 0]]\n",
      "output = [[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "G = np.random.choice(a=[0, 1], size=(3, 3), p=[0.5, 0.5])\n",
    "print(f\"G = \\n{G}\")\n",
    "G = tf.convert_to_tensor(G.reshape(1,3,3))\n",
    "M = make_explicit_model()\n",
    "print(f\"output = {M.predict(G, verbose=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the function below tests whether the model output classifies all possible 512 3x3 images correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_explicit_model(M=M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.2\n",
    "\n",
    "We now demonstrate the convolutional model using the kernels from the model above to search for letters in a grid of height $h$ and width $w$. The variable `word` can be set to any word containing our specified letters, and the function `make_ragged_grid()` will choose appropriate values for $h$ and $w$ and create a grid containing the word.\n",
    "\n",
    "The output of the model contains a series of one-hot vectors showing the detected letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADMUlEQVR4nO3YQY7CMBAAwXiV/3959soxAgWjdNU5QgOOhpbXzMwBAGT97R4AANhLDABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACDuvPrgWuvOOR5jZnaPAD/JDrnGDmEHNwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIO3cP8Gpmdo/Aw6y1bv187+x13/itnPfvuPssjuP+83jCd7jKzQAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHHn7gFerbV2j/Cxmdk9AsB239iFd/9nlPa5mwEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEnVcfnJk75wD4mD0F73EzAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgLg1M7N7CABgHzcDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAg7h9GFzBAReqNnQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "GM = make_conv_model(G.shape[1], G.shape[2])\n",
    "print(GM.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.3\n",
    "\n",
    "This example demonstrates the model above with the additional of a layer to count up the occurences of each letter. The output is a single vector containing the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADPUlEQVR4nO3cQU7DQBBFQQb5/ldutixBJG6SV3WBfMd29DSLnJmZDwAg63N7AACwSwwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABB3bQ8A4P2cc57+Gc/+z7x3uIafcjIAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAuGt7ALDvnLM94SXMzPaEl3HHd/Xs57Z0v50MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIO7aHvDdOWd7wkuYme0JL+PZz9S73Is7ruOO9/td7gfczckAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABx1/aAu83M9gQAHsDv+eM4GQCAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAEDctT3gbuec7Ql/NjPbE+DXPLfwfzkZAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQNyZmdkeAQDscTIAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADivgB+ZTBCAYSWzwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [1.]\n",
      "   [0.]\n",
      "   [0.]]]]\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "SM = make_sum_model(G.shape[1], G.shape[2])\n",
    "print(SM.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.4\n",
    "\n",
    "The following code demonstrates the model that recognises words. The output will be a series of integers from 1 to 10 representing each letter. The sequence is sorted so that the detected letters are moved to the front of the sequence, and the zeros are moved to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADKUlEQVR4nO3YQYrDMBAAwWjx/788e83REGzF6aqzIeNIhmbWzMwLAMj62z0AALCXGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAEDcsXsAoGGttXuER5iZy3/jjrP4hfe44x2+hc0AAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4tbMzKkH17p6lp9w8u/kdc+dch4tV98p9+k83/ez2AwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABB37B7g3czsHgEAcmwGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAEHfsHuDdWmv3CB+bmd0jQJbv73s4i2exGQCAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAEDcmpnZPQQAsI/NAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiPsHctUuP8mfl5IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 1. 8. 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "GRUM = make_gru_model(G.shape[1], G.shape[2])\n",
    "print(GRUM.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the output at various stages to verify the model is working as described. The code below shows the output of layer $\\mathcal{L}^{\\left[3\\right]}$, which is the sequence $\\left\\{x_t\\right\\}_{t=1}^{w_g}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EA796CEC20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[[4. 1.]\n",
      "  [1. 1.]\n",
      "  [0. 0.]\n",
      "  [8. 1.]\n",
      "  [0. 0.]\n",
      "  [2. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_integers = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[5].output)\n",
    "print(GRUM_integers.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to produce the sequence $\\left\\{s_t\\right\\}_{t=1}^{w_g}$ in layer $\\mathcal{L}^{\\left[4\\right]}$, shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 21 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EA796CF250> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[[1.]\n",
      "  [2.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [3.]\n",
      "  [4.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_indicator = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[6].output)\n",
    "print(GRUM_indicator.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to produce the series of positional indicators $\\left\\{o_{w_g}(s_t)\\right\\}_{t=1}^{w_g}$ in layer $\\mathcal{L}^{\\left[8\\right]}$, shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_position = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[10].output)\n",
    "print(GRUM_position.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full combination passed to the final GRU layer is then as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4. 1. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [8. 1. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [2. 1. 0. 0. 0. 1. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_final_input = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[11].output)\n",
    "print(GRUM_final_input.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.5\n",
    "\n",
    "The alternative model below shows how the sequence $\\left\\{o_{w_g}(s_t)\\right\\}_{t=1}^{w_g}$ could also be created in a more intuitive way using a GRU layer with an initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADRUlEQVR4nO3cwW6DMBQAwbri/3/59ZpLJdIKHLEzZyQesUlWPmTNzHwBAFnfuwcAAPYSAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxB1nL1xrXTnHY/gPp89y9b613sATOBkAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABA3LF7gFczs3sEgMdba11+jzu+z69+jtJvkpMBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxB27B3i11to9wr/NzO4R4G1PePfu8JT3+47nuGNPPWU9PoGTAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4o6zF87MlXPAJezbc+74nNZal9/DesPfOBkAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABA3LF7AACeZ2Z2j8AbnAwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAg7tg9ANAwM7tHAH7hZAAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMT9AKYgMkN+3WNaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to GRU layer:\n",
      " [[[4. 1.]\n",
      "  [0. 0.]\n",
      "  [1. 1.]\n",
      "  [8. 1.]\n",
      "  [0. 0.]\n",
      "  [2. 1.]]]\n",
      "Output of GRU layer:\n",
      " [[[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0.]]]\n",
      "Final output:\n",
      " [[4. 1. 8. 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "GRUaM = make_alt_gru_model(G.shape[1], G.shape[2])\n",
    "\n",
    "GRUaM_indicator = tf.keras.Model(inputs=GRUaM.input, outputs=GRUaM.layers[5].output)\n",
    "print(f\"Input to GRU layer:\\n {GRUaM_indicator.predict(G, verbose=0)}\")\n",
    "\n",
    "GRUaM_position = tf.keras.Model(inputs=GRUaM.input, outputs=GRUaM.layers[6].output)\n",
    "print(f\"Output of GRU layer:\\n {GRUaM_position.predict(G, verbose=0)}\")\n",
    "\n",
    "print(f\"Final output:\\n {GRUaM.predict(G, verbose=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.6\n",
    "\n",
    "A full model with lookup layers added can be tested below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADJ0lEQVR4nO3cQWqFMBRAUVPc/5Zfpx0K5Set95wFyJMkcsnANTNzAQBZX6cHAADOEgMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMTdpwf4aa11eoR/wX+invv0nrIWzznfz+zYUzvW4g3vUTrfbgYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQd58eYLeZOT0CJO04e2utjz7/Ld+PN6zFdb1nPf4CNwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIu08PsNta6/QIvzYzp0cA4EXcDABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAELdmZk4PAQCc42YAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABD3DY0nKkSKwqOZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "FM = make_full_model(G.shape[1], G.shape[2])\n",
    "# decode() just takes the raw string from the tensor object\n",
    "[print(z.decode()) for z in FM.predict(G, verbose=0).reshape(1,)]\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure code\n",
    "\n",
    "The following code produces the figures contained in this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.random.set_seed(210138711)\n",
    "\n",
    "word = 'city'\n",
    "G = G_orig = make_ragged_grid(word)\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "FM = make_full_model(G.shape[1], G.shape[2])\n",
    "word_out = [z.decode() for z in FM.predict(G, verbose=0).reshape(1,)]\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G_orig, cmap='gray')\n",
    "plt.title(f'word in = {word}, word out = {word_out}')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
