{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letters\n",
    "\n",
    "Run the source code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"code\\letters.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', 'chi', 'chic', 'chichi', 'chili', 'chill', 'chilli', 'chilly', 'chit', 'chou', 'ci', 'city', 'cl', 'clio', 'clot', 'cloth', 'clotho', 'clout', 'cloy', 'clutch', 'co', 'cocci', 'coccyx', 'coil', 'col', 'colic', 'colo', 'colt', 'coo', 'cool', 'coolly', 'coot', 'cot', 'couch', 'cox', 'coy', 'coyly', 'cthulhu', 'cu', 'cull', 'cult', 'cut', 'cyclic', 'h', 'hi', 'hill', 'hilly', 'hilt', 'hit', 'hitch', 'ho', 'hohhot', 'holly', 'holt', 'holy', 'hooch', 'hoot', 'hootch', 'hot', 'hotly', 'huh', 'hui', 'hull', 'hut', 'hutch', 'hutu', 'i', 'icily', 'icy', 'ill', 'illicit', 'illicitly', 'io', 'it', 'itch', 'itchy', 'ito', 'j', 'jill', 'jilt', 'jo', 'jollity', 'jolly', 'jolt', 'jot', 'joy', 'juicy', 'jul', 'julio', 'july', 'jut', 'l', 'li', 'licit', 'lilith', 'lilly', 'lilt', 'lily', 'lit', 'litchi', 'lo', 'loci', 'loco', 'loll', 'loot', 'lot', 'loth', 'lott', 'lotto', 'lou', 'lout', 'lox', 'lt', 'lu', 'lucio', 'lucy', 'lull', 'lully', 'lulu', 'lyly', 'lyx', 'o', 'occult', 'oct', 'oh', 'ohio', 'oho', 'oil', 'oilcloth', 'oily', 'otto', 'ouch', 'out', 'ox', 't', 'tc', 'th', 'tho', 'thoth', 'thou', 'thy', 'ti', 'tic', 'till', 'tillich', 'tilt', 'tit', 'tito', 'tl', 'to', 'toil', 'tojo', 'toll', 'too', 'tool', 'toot', 'tooth', 'toothy', 'tot', 'toto', 'touch', 'touchy', 'tout', 'toxic', 'toxicity', 'toy', 'tull', 'tut', 'tutu', 'tux', 'ty', 'tycho', 'u', 'uh', 'utility', 'x', 'y', 'yo', 'you', 'youth'] [4, 202, 5526, 269064, 22829, 96034, 257085, 418136, 10850, 12665, 15, 3645, 70, 6846, 11323, 113810, 919065, 129782, 3337, 1197728, 59, 20508, 1645659, 8166, 785, 60680, 7440, 11433, 664, 8650, 418598, 11312, 1027, 108959, 1269, 301, 37569, 17172170, 103, 8815, 11477, 1071, 667341, 7, 18, 8730, 38012, 11392, 986, 108797, 62, 1371839, 38056, 11436, 3450, 108478, 11315, 1197236, 1030, 38298, 953, 227, 8818, 1074, 108885, 13053, 1, 37434, 287, 793, 14394227, 560035015, 56, 89, 9890, 39172, 694, 3, 8726, 11388, 58, 4854941, 38052, 11432, 1026, 300, 34829, 828, 75364, 3490, 1070, 6, 17, 118960, 1246559, 38011, 11391, 3405, 985, 269847, 61, 1876, 7200, 8773, 11314, 1029, 10346, 11677, 84882, 1150, 11798, 1271, 94, 105, 75125, 3251, 8817, 38099, 12810, 3416, 1238, 5, 1388766, 1017, 82, 6858, 687, 742, 151481852, 3404, 7716, 9905, 1072, 115, 8, 52, 85, 690, 113825, 12669, 327, 19, 503, 8731, 13068503, 11393, 987, 7642, 74, 63, 8170, 7081, 8775, 668, 8654, 11316, 113803, 435905, 1031, 7686, 108963, 431065, 11800, 61168, 53369049, 305, 8819, 1075, 13054, 1317, 30, 83036, 9, 86, 4854375, 10, 2, 57, 1146, 114281]\n"
     ]
    }
   ],
   "source": [
    "words_3x3, numbers_3x3 = make_2vocab(file='words_3x3.txt')\n",
    "print(words_3x3, numbers_3x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.1\n",
    "\n",
    "Here we demonstrate the kernels to detect a letter from its representation in a 3x3 grid. Modify `letter` to any of the given letters and check the output is the one-hot encoding of the letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G = \n",
      "[[1 1 1]\n",
      " [1 0 0]\n",
      " [1 1 1]]\n",
      "output = [[[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "# The letters in order are i,y,j,c,o,l,h,t,u,x\n",
    "letter = 'c'\n",
    "\n",
    "G = letter_pixels[letter]\n",
    "print(f\"G = \\n{G}\")\n",
    "G = tf.convert_to_tensor(G.reshape(1,3,3))\n",
    "M = make_explicit_model()\n",
    "print(f\"output = {M.predict(G, verbose=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check that it rejects non-letters by setting the output to all zeros. A random choice of `G` will give us a non-letter 502 times out of 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G = \n",
      "[[1 0 0]\n",
      " [1 0 1]\n",
      " [1 1 0]]\n",
      "output = [[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "G = np.random.choice(a=[0, 1], size=(3, 3), p=[0.5, 0.5])\n",
    "print(f\"G = \\n{G}\")\n",
    "G = tf.convert_to_tensor(G.reshape(1,3,3))\n",
    "M = make_explicit_model()\n",
    "print(f\"output = {M.predict(G, verbose=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the function below tests whether the model output classifies all possible 512 3x3 images correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_explicit_model(M=M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.2\n",
    "\n",
    "We now demonstrate the convolutional model using the kernels from the model above to search for letters in a grid of height $h$ and width $w$. The variable `word` can be set to any word containing our specified letters, and the function `make_ragged_grid()` will choose appropriate values for $h$ and $w$ and create a grid containing the word.\n",
    "\n",
    "The output of the model contains a series of one-hot vectors showing the detected letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADOElEQVR4nO3YQW6EQBAEQY/F/7/cvvpqeZcWmxEfoCQYlJozM/MFAGR9bw8AAHaJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMRd2wN+O+dsT3iEmdme8Bjv/qa8C57ojn/tHWfD+X4dNwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIu7YH3G1mtidA0jlne8Ij3PGPuuMZd7xv//PXcTMAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAEDctT3gbuec7Qn/NjPbE+DP7vhu332+nT0+lZsBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxF3bA36bme0JfBjfFOxw9p7FzQAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADiru0BAK8yM9sT4JHcDABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgLgf42cyQR3Jr6IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "   [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "GM = make_conv_model(G.shape[1], G.shape[2])\n",
    "print(GM.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.3\n",
    "\n",
    "This example demonstrates the model above with the additional of a layer to count up the occurences of each letter. The output is a single vector containing the counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADNElEQVR4nO3cQW7CQBAAwWzk/395uHIkCvaCu+oBaCx2TWsOrJmZHwAg63f3AADAXmIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIC4Y/cAz9Zau0f4Cv4nCvh0V7zPz34X3uEZXmUzAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgLhj9wBXm5ndI3Chtdapn+88ve7s7+Iu7nKmrngO9/t9bAYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQd+we4Gprrd0j/NvM7B4B/uyKc3v2/Xb3uCubAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4o7dAzybmd0jAPAl/Ga8j80AAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4tbMzO4hAIB9bAYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAuAdxQDBA5zFg3gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "SM = make_pq_conv_model(G.shape[1], G.shape[2])\n",
    "print(SM.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.4\n",
    "\n",
    "The following code demonstrates the model that recognises words. The output will be a series of integers from 1 to 10 representing each letter. The sequence is sorted so that the detected letters are moved to the front of the sequence, and the zeros are moved to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADPklEQVR4nO3cQW7CQBAAwWzk/395cuWQSI6CvZG76mzBILymNQfWzMwHAJD1uXsAAGAvMQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQNxx9sK11pVzPIb/cAK45zfj6uftEz7DWTYDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiDt2D/BqZnaPwMOstS59ffcsfO+Os+F8v4/NAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOKO3QO8WmvtHuHPZmb3CPBrTzh7d3C+eSqbAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4o6zF87MlXMAG91xvtdal7+H51SL7/t9bAYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQd+weAK40M7tHAPj3bAYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQd+weAGiYmd0jAD+wGQCAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFfU10yQ4eUePwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 1. 8. 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "GRUM = make_gru_model(G.shape[1], G.shape[2])\n",
    "print(GRUM.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the output at various stages to verify the model is working as described. The code below shows the output of layer $\\mathcal{L}^{\\left[3\\right]}$, which is the sequence $\\left\\{x_t\\right\\}_{t=1}^{w_g}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [8.]\n",
      "  [0.]\n",
      "  [2.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_integers = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[5].output)\n",
    "print(GRUM_integers.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to produce the sequence of indicators in layer $\\mathcal{L}^{\\left[5\\right]}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_indicator = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[7].output)\n",
    "print(GRUM_indicator.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is used to produce the series of positional indicators $\\left\\{\\pmb{p}_t\\right\\}_{t=1}^{w_g}$ in layer $\\mathcal{L}^{\\left[8\\right]}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_position = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[10].output)\n",
    "print(GRUM_position.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full combination passed to the final GRU layer is then as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 1. 0. 0. 0. 0.]\n",
      "  [8. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0.]\n",
      "  [2. 0. 0. 0. 1. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "GRUM_final_input = tf.keras.Model(inputs=GRUM.input, outputs=GRUM.layers[13].output)\n",
    "print(GRUM_final_input.predict(G, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.5\n",
    "\n",
    "The alternative model below shows how the sequence $\\left\\{\\pmb{p}_t\\right\\}_{t=1}^{w_g}$ could also be created in a more intuitive way using a GRU layer with an initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADN0lEQVR4nO3cwW3DQBAEQZ/B/FNevww4AIsrqqsS4EgUicY9dGZmvgCArO/tAQDALjEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAEDctT0A2HfO2Z7wCP6jjU/lZAAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABx1/YAus45L7/GzLz8Gp/gju/J/X4fn3IvXv05Sr8nJwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIu7YH/HXO2Z7wCDOzPQF4sDveIXe8z70L/4+TAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4q7tAXebme0JkOTZg/flZAAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxZ2Zme8Svc872hEd4o1sGwAdwMgAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIC4a3vAXzOzPQEAcpwMAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAuB/4wzBCPID85AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to GRU layer:\n",
      " [[[1.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]\n",
      "  [0.]\n",
      "  [1.]]]\n",
      "Output of GRU layer:\n",
      " [[[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0.]]]\n",
      "Final output:\n",
      " [[4. 1. 8. 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "GRUaM = make_alt_gru_model(G.shape[1], G.shape[2])\n",
    "\n",
    "GRUaM_indicator = tf.keras.Model(inputs=GRUaM.input, outputs=GRUaM.layers[7].output)\n",
    "print(f\"Input to GRU layer:\\n {GRUaM_indicator.predict(G, verbose=0)}\")\n",
    "\n",
    "GRUaM_position = tf.keras.Model(inputs=GRUaM.input, outputs=GRUaM.layers[8].output)\n",
    "print(f\"Output of GRU layer:\\n {GRUaM_position.predict(G, verbose=0)}\")\n",
    "\n",
    "print(f\"Final output:\\n {GRUaM.predict(G, verbose=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.6\n",
    "\n",
    "A full model with lookup layers added can be tested below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAACoCAYAAAB9n+1TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAADPElEQVR4nO3cO3KEMBBAQcvF/a88Th0SrJDN645VMLt86pUC1szMFwCQ9X16AADgLDEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAEDcdXoAAJ611tp+jie+Z7f7d5S+yWdnAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHHX6QFgp7XW1uPPzNbjv8nua/EWT9xTT5zjievt+fscOwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIEwMAECcGACBODABAnBgAgDgxAABxYgAA4sQAAMSJAQCIu+4uXGvtnOM1Zub0CPAnPfFs7H5Peb55KzsDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEXacH+G1mTo8AwAd4n/8vdgYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQt2Zmbi1ca/csr3Dz7wSAP8POAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOLEAADEiQEAiBMDABAnBgAgTgwAQJwYAIA4MQAAcWIAAOKuuwtnZuccAMAhdgYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAECcGACAODEAAHFiAADixAAAxIkBAIgTAwAQJwYAIE4MAEDcDzdoMELEHA/1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city\n"
     ]
    }
   ],
   "source": [
    "word = 'city'\n",
    "\n",
    "G = make_ragged_grid(word)\n",
    "plt.axis('off')\n",
    "plt.imshow(1-G, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "G = tf.convert_to_tensor(G.reshape(1, G.shape[0], G.shape[1]))\n",
    "FM = make_full_model(G.shape[1], G.shape[2])\n",
    "# decode() just takes the raw string from the tensor object\n",
    "[print(z.decode()) for z in FM.predict(G, verbose=0).reshape(1,)]\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(FM)\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
